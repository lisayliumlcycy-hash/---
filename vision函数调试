from enum import Enum
from collections import namedtuple

import cv2
import numpy as np
import time 

# æ³¨æ„ï¼šè¯·ç¡®ä¿ exceptions.py å­˜åœ¨ ChessboardNotFoundError ç±»ï¼Œå¦åˆ™éœ€è¦åˆ é™¤æˆ–æ³¨é‡Šæ‰è¿™ä¸€è¡Œ
# from exceptions import ChessboardNotFoundError 


# å›¾åƒå°ºå¯¸
width, height = 640, 480
# è°ƒè¯•å¼€å…³ï¼Œæ§åˆ¶æ˜¯å¦æ˜¾ç¤º 64 ä¸ªå°æ–¹å—å’Œ FloodFill ç»“æœ
debug_windows_enabled = True 
# æ£‹å­è¯†åˆ«æ–¹æ³•: True ä½¿ç”¨äº®åº¦ç»Ÿè®¡, False ä½¿ç”¨ FloodFill (å·²åºŸå¼ƒ)
use_robust_detection = True 


Point = namedtuple("Point", ["x", "y"])


# Colors in BGR mode, used by opencv.
class Colors(Enum):
    white = (255, 255, 255)
    black = (0, 0, 0)
    blue = (255, 0, 0)
    green = (0, 255, 0)
    red = (0, 0, 255)


# The "type" of a piece is the color of the pattern, not the background.
class SquareType(Enum):
    empty = 0
    white = 1
    black = 2

    def __str__(self):
        if self == SquareType.empty:
            return ' '
        if self == SquareType.white:
            return 'o'
        if self == SquareType.black:
            return 'x'
        return None

# ==============================================================================
# æ ¸å¿ƒå‡½æ•°: è§’ç‚¹æ£€æµ‹ (find_corners)
# ==============================================================================

# Returns the four corners of the chessboard, or None if not found.
def find_corners(image):
    # Draw a circle at [center] with [radius]
    def draw_circle(image, center, radius=1, color=Colors.white):
        cv2.circle(image, center, radius, color.value, 2)

    # å½¢æ€å­¦æ“ä½œï¼Œç”¨äºæ¸…é™¤å™ªç‚¹å’Œå¡«å……æ ‡è®°ç‚¹å†…éƒ¨ç©ºæ´
    def clean_mask(mask, kernel_size=(5, 5)):
        kernel = np.ones(kernel_size, np.uint8)
        mask = cv2.morphologyEx(mask, cv2.MORPH_OPEN, kernel)
        mask = cv2.morphologyEx(mask, cv2.MORPH_CLOSE, kernel)
        return mask

    # Return a new image converted to black & white
    def threshold(image):
        blurred = cv2.blur(image, (10, 10))
        ret, thresholded = cv2.threshold(blurred, 200, 255, cv2.THRESH_BINARY)
        return thresholded

    # Extract center point from largest contour in a black & white image
    def find_point(image):
        def center(contour):
            x, y, w, h = cv2.boundingRect(contour)
            return Point(x + w // 2, y + h // 2)

        # å…¼å®¹ OpenCV 3/4
        try:
            _, contours, _ = cv2.findContours(
                image, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE,
            )
        except:
             contours, _ = cv2.findContours(
                image, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE,
            )

        if len(contours) < 1:
            return None
        contour = max(contours, key=cv2.contourArea)
        return center(contour)

    hsv = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)
    masks = [
        # 1. Red 
        cv2.inRange(hsv, (0, 89, 135), (14, 255, 247)),
        # 2. Green
        cv2.inRange(hsv, (52, 69, 77), (72, 226, 254)),
        # 3. Blue
        cv2.inRange(hsv, (89, 79, 93), (116, 178, 233)),
        # 4. Pink/Purple 
        cv2.inRange(hsv, (136, 55, 71), (150, 255, 212)),
    ]
    
    # å¯¹æ¯ä¸ª Mask å…ˆè¿›è¡Œå½¢æ€å­¦æ¸…ç†ï¼Œå†è¿›è¡Œé˜ˆå€¼å¤„ç†å’Œæ‰¾ç‚¹
    points = [find_point(threshold(clean_mask(mask))) for mask in masks]

    if not all(points):
        return None

    # ... (åæ ‡è°ƒæ•´éƒ¨åˆ†ä¿æŒä¸å˜) ...
    x0, y0 = points[0]
    x1, y1 = points[1]
    x2, y2 = points[2]
    x3, y3 = points[3]

    adjusted_points = [
        Point(
            int(x0 + (x0 - x1) * 0.00 - (x0 - x2) * 0.05),
            int(y0 + (y0 - y1) * 0.00 - (y0 - y2) * 0.05),
        ),
        Point(
            int(x1 + (x1 - x0) * 0.08 - (x1 - x3) * 0.05),
            int(y1 + (y1 - y0) * 0.08 - (y1 - y3) * 0.05),
        ),
        Point(
            int(x2 + (x2 - x3) * 0.02 - (x2 - x0) * 0.05),
            int(y2 + (y2 - y3) * 0.02 - (y2 - y0) * 0.05),
        ),
        Point(
            int(x3 + (x3 - x2) * 0.08 - (x3 - x1) * 0.05),
            int(y3 + (y3 - y2) * 0.08 - (y3 - y1) * 0.05),
        ),
    ]

    return adjusted_points


# Returns a new image after a perspective transform,
# moving [corners] to the corners of the image.
def transform(image, corners):
    src = np.array(
        [
            (corners[0].x, corners[0].y),
            (corners[1].x, corners[1].y),
            (corners[2].x, corners[2].y),
            (corners[3].x, corners[3].y),
        ], np.float32)

    dst = np.array(
        [
            (0, 0),
            (width, 0),
            (0, height),
            (width, height),
        ], np.float32)

    matrix = cv2.getPerspectiveTransform(src, dst)
    return cv2.warpPerspective(image, matrix, (width, height))

# ==============================================================================
# é²æ£’è¯†åˆ«å‡½æ•° (detect_square_type_robust)
# ==============================================================================

def detect_square_type_robust(image):
    """
    åŸºäºä¸­å¿ƒåŒºåŸŸçš„å¹³å‡äº®åº¦å’Œæ ‡å‡†å·®ç»Ÿè®¡æ¥è¯†åˆ«æ£‹å­ç±»å‹
    """
    # 1. è½¬ç°åº¦
    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
    
    # 2. æˆªå–ä¸­å¿ƒåŒºåŸŸï¼ˆé¿å¼€æ ¼å­è¾¹æ¡†ï¼‰
    h, w = gray.shape
    roi = gray[int(h*0.2):int(h*0.8), int(w*0.2):int(w*0.8)]
    
    # 3. è®¡ç®—ç»Ÿè®¡é‡
    mean_val = np.mean(roi) # å¹³å‡äº®åº¦ (0-255)
    std_dev = np.std(roi)  # æ ‡å‡†å·®ï¼ˆçº¹ç†å¤æ‚åº¦ï¼‰
    
    if debug_windows_enabled:
        print(f"[{mean_val:.1f}, {std_dev:.1f}]", end=" ")

    square_type = SquareType.empty
    
    # --- é˜ˆå€¼è®¾ç½® (è¯·æ ¹æ®å®é™…è§‚å¯Ÿè°ƒæ•´) ---
    if mean_val > 180: 
        square_type = SquareType.white
    elif mean_val < 60:
        square_type = SquareType.black
    else:
        square_type = SquareType.empty
        
    # åˆ›å»ºè°ƒè¯•å›¾åƒ: å°† ROI åŒºåŸŸçš„äº®åº¦ç»Ÿè®¡ç»“æœç”»åœ¨å›¾åƒä¸Š
    debug_image = image.copy()
    cv2.putText(debug_image, f"M:{mean_val:.1f} S:{std_dev:.1f}", (5, 20), 
                cv2.FONT_HERSHEY_SIMPLEX, 0.4, Colors.red.value, 1)
    
    return square_type, debug_image

# å…¼å®¹åŸæœ‰çš„ FloodFill é€»è¾‘ï¼Œä½†ç°åœ¨è°ƒç”¨é²æ£’å‡½æ•°
def detect_square_type(image):
    return detect_square_type_robust(image)

# ==============================================================================
# ä¸»è¯†åˆ«æµç¨‹ (get_position_from_image)
# ==============================================================================

def get_position_from_image(image):
    # Crop the image into 8x8 squares.
    def crop(image, i, j):
        w = int(width / 8)
        h = int(height / 8)
        return image[h * j : h * (j + 1), w * i : w * (i + 1)]

    # 1. å¯»æ‰¾è§’ç‚¹
    corners = find_corners(image)
    if corners is None:
        return None

    # 2. é€è§†å˜æ¢
    chessboard_image = transform(image, corners)

    # 3. è°ƒè¯•ï¼šæ˜¾ç¤ºé€è§†å˜æ¢å›¾
    if debug_windows_enabled:
        cv2.imshow("1. Chessboard Perspective", chessboard_image)

    # 4. æ£‹å­è¯†åˆ«å’Œæ‰“åŒ…å¯è§†åŒ–ç»“æœ
    position = []
    debug_squares = [] 
    
    print("\n--- è¯†åˆ«ç»Ÿè®¡é‡ [Mean, StdDev] ---")
    
    for j in range(8):
        row = []
        debug_row = [] 
        print(f"Rank {8-j}: ", end="")
        for i in range(8):
            cropped_square = crop(chessboard_image, i, j)
            
            # è°ƒç”¨é²æ£’è¯†åˆ«å‡½æ•°
            square_type, debug_img = detect_square_type_robust(cropped_square)
            
            row.append(square_type)

            # åœ¨è°ƒè¯•å›¾ä¸Šæ ‡è®°è¯†åˆ«ç»“æœ
            label = str(square_type)
            cv2.putText(debug_img, label, (5, 40), cv2.FONT_HERSHEY_SIMPLEX, 0.5, Colors.blue.value, 2)

            # æ°´å¹³æ‹¼æ¥ï¼š[åŸå§‹æ ¼å­ | è°ƒè¯•ç»“æœ (å¸¦ç»Ÿè®¡é‡)]
            combined_square = np.hstack((cropped_square, debug_img))
            debug_row.append(combined_square)

        position.append(row)
        if debug_windows_enabled:
            print() # æ¢è¡Œ
            
        if debug_row:
            # å‚ç›´æ‹¼æ¥ 8 ä¸ª [åŸå§‹æ ¼å­ | è°ƒè¯•ç»“æœ] å›¾åƒ
            debug_squares.append(np.hstack(debug_row)) 

    # 5. æ˜¾ç¤ºæ‰“åŒ…å¥½çš„ 64 ä¸ªæ ¼å­å’Œè°ƒè¯•ç»“æœ
    if debug_windows_enabled and debug_squares:
        final_debug_display = np.vstack(debug_squares)
        
        # ç¼©æ”¾æ˜¾ç¤º (é¿å…çª—å£è¿‡å¤§)
        scale_factor = 0.5
        display_h, display_w = final_debug_display.shape[:2]
        final_debug_display_resized = cv2.resize(final_debug_display, 
                                                (int(display_w * scale_factor), int(display_h * scale_factor)))
        
        cv2.imshow("4. 64 Squares + Robust Detection Debug (Resized)", final_debug_display_resized)

    return position

# ==============================================================================
# ä¸»å‡½æ•°å’Œæ‘„åƒå¤´è°ƒç”¨ - æ‘„åƒå¤´ç´¢å¼•å·²ä¿®æ”¹ä¸º 1
# ==============================================================================

def main():
    # ğŸ¯ å…³é”®ä¿®æ”¹: å°è¯•æ‰“å¼€æŒ‡å®šçš„æ‘„åƒå¤´ç´¢å¼• 1
    CAMERA_INDEX = 1
    print(f"ğŸš€ å°è¯•æ‰“å¼€æ‘„åƒå¤´ (ç´¢å¼• {CAMERA_INDEX})...")
    cap = cv2.VideoCapture(CAMERA_INDEX) 
    cap.set(cv2.CAP_PROP_FRAME_WIDTH, width)
    cap.set(cv2.CAP_PROP_FRAME_HEIGHT, height)

    # 2. æ‘„åƒå¤´å¯è§†åŒ–ç­‰å¾…æœºåˆ¶
    if not cap.isOpened():
        print(f"âŒ æ— æ³•æ‰“å¼€æ‘„åƒå¤´ (ç´¢å¼• {CAMERA_INDEX})ã€‚è¯·æ£€æŸ¥è®¾å¤‡è¿æ¥æˆ–æ›´æ”¹ç´¢å¼•ã€‚")
        return

    # æ‘„åƒå¤´æ‰“å¼€ç­‰å¾…/åˆå§‹åŒ–å¾ªç¯
    print("â³ æ‘„åƒå¤´å·²è¿æ¥ã€‚æ­£åœ¨ç­‰å¾…ç”»é¢ç¨³å®š...")
    
    # åˆ›å»ºä¸€ä¸ªç”¨äºæç¤ºçš„ç©ºç™½å›¾åƒ
    wait_frame = np.zeros((height, width, 3), dtype=np.uint8)
    cv2.putText(wait_frame, f"Camera Index {CAMERA_INDEX} Initializing...", (100, 240), 
                cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)
    
    max_wait_time = 5 # æœ€å¤šç­‰å¾… 5 ç§’
    start_time = time.time()
    camera_ready = False
    
    while time.time() - start_time < max_wait_time:
        ret, frame = cap.read()
        
        if ret:
            # è¯»å–æˆåŠŸï¼Œæ˜¾ç¤ºå®æ—¶ç”»é¢å¹¶ç¡®è®¤
            frame = cv2.resize(frame, (width, height))
            cv2.imshow("0. Original Image", frame)
            cv2.waitKey(1)
            camera_ready = True
            break
        else:
            # è¯»å–å¤±è´¥ï¼Œæ˜¾ç¤ºç­‰å¾…æç¤ºï¼Œå¹¶ç­‰å¾…ä¸€å°æ®µæ—¶é—´
            cv2.imshow("0. Original Image", wait_frame)
            cv2.waitKey(50) 
            time.sleep(0.1)

    if not camera_ready:
        print("âŒ æ‘„åƒå¤´é•¿æ—¶é—´æœªå‡†å¤‡å°±ç»ªã€‚é€€å‡ºã€‚")
        cap.release()
        cv2.destroyAllWindows()
        return

    print("âœ… æ‘„åƒå¤´ç”»é¢ç¨³å®šï¼æŒ‰ 'q' é”®é€€å‡ºã€‚")

    # 3. ä¸»å¾ªç¯å¼€å§‹
    while True:
        ret, frame = cap.read()
        if not ret:
            print("âŒ æ— æ³•è¯»å–å¸§ã€‚")
            break

        frame = cv2.resize(frame, (width, height))
        
        # å®æ—¶æ›´æ–°åŸå§‹å›¾åƒçª—å£
        cv2.imshow("0. Original Image", frame) 
        
        try:
            position = get_position_from_image(frame)
            
            if position:
                print("\n" + "=" * 20)
                print("â™Ÿï¸ è¯†åˆ«ç»“æœ:")
                print("  a b c d e f g h")
                print("-" * 17)
                
                # æ‰“å° 8x8 æ£‹ç›˜
                for k in range(8):
                    rank = 8 - k 
                    row_str = " ".join([str(p) for p in position[k]])
                    print(f"{rank}|{row_str}")
                print("=" * 20)

        except Exception as e:
            print(f"âš ï¸ è¯†åˆ«è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}")

        # æ˜¾ç¤ºæ‰€æœ‰ OpenCV çª—å£ï¼Œå¹¶ç­‰å¾…æŒ‰é”®
        key = cv2.waitKey(1)
        if key & 0xFF == ord('q'):
            break

    # æ¸…ç†
    cap.release()
    cv2.destroyAllWindows()


if __name__ == "__main__":
    main()
